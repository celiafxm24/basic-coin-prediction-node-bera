services:
  inference:
    container_name: inference
    env_file:
      - .env
    build: .
    command: python -u /app/app.py
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://inference:8000/inference/${TOKEN}"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 120s
    volumes:
      - ./inference-data:/app/data
  
  updater:
    container_name: updater
    build: .
    environment:
      - INFERENCE_API_ADDRESS=http://inference:8000
    command: >
      sh -c "while [ ! -f /app/data/price_data.csv ]; do echo 'Waiting for price_data.csv...'; sleep 10; done && cp /app/data/price_data.csv /app/data/raw_bera.csv && echo 'Copied price_data.csv to raw_bera.csv' && while true; do python -u /app/update_app.py; sleep 2h; done"
    depends_on:
      inference:
        condition: service_healthy
    volumes:
      - ./inference-data:/app/data

  worker:
    container_name: worker
    image: alloranetwork/allora-offchain-node:v0.9.1
    volumes:
      - ./worker-data:/app/data
    depends_on:
      inference:
        condition: service_healthy
    env_file:
      - ./worker-data/env_file

volumes:
  inference-data:
  worker-data:
